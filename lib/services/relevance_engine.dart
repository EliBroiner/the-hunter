import 'package:flutter/foundation.dart';
import '../configs/ranking_config.dart';
import '../models/file_metadata.dart';
import '../utils/smart_search_parser.dart';

/// ×× ×•×¢ ×¨×œ×•×•× ×˜×™×•×ª â€” ××™×•×Ÿ ××—×™×“ ×œ×ª×•×¦××•×ª ××§×•××™×•×ª, Drive ×•-AI; ××©×§×œ×™× × ×œ×§×—×™× ×Ö¾RankingConfig
class RelevanceEngine {
  RelevanceEngine._();

  static const double _synonymFactor = 0.7;
  static const int _aiMetadataBonus = 80;
  /// ×‘×•× ×•×¡ ×œ-Drive: ××™×Ÿ ×ª×•×›×Ÿ ××—×•×œ×¥ â€” ×”×ª×××•×ª ×‘×©× ×§×•×‘×¥ ×©×•×§×œ×•×ª ×™×•×ª×¨ ×›×“×™ ×œ××–×Ÿ ××•×œ ××§×•××™
  static const double _driveMetadataBonus = 55.0;
  /// ×‘×•× ×•×¡ ×¡××™×›×•×ª: ×–×•×’×•×ª ××•× ×—×™ ×©××™×œ×ª×” ×©××•×¤×™×¢×™× consecutively ×‘×ª×•×›×Ÿ (××§×¡×™××•× 4 ×–×•×’×•×ª = 100 × ×§×•×“×•×ª)
  static const double _adjacentPairBonus = 25.0;
  static const int _adjacentPairCap = 4;
  static const double _multiWordSeverePenalty = 0.2;
  static const double _multiWordFullBonusAdd = 50.0;
  /// ×§× ×¡ ×œ×©× ××¢×¨×›×ª/×§×¨×™×¤×˜×™ â€” ×¦×™×•×Ÿ × ×™×™×˜×¨×œ×™ ×œ×©×¤×”
  static const double _crypticNamePenalty = -35.0;
  static final RegExp _guidLikeName = RegExp(r'^[a-fA-F0-9\-]{20,}$');
  static final RegExp _pdfDotNumbers = RegExp(r'^pdf\.\d+', caseSensitive: false);

  static bool _isAllDigits(String s) =>
      s.isNotEmpty && s.split('').every((c) => c.codeUnitAt(0) >= 0x30 && c.codeUnitAt(0) <= 0x39);

  /// ×”×ª×××ª ××•× ×— â€” ××—×¨×™ × ×¨××•×œ (× ×™×§×•×“, ×¨×•×•×—×™×, ×œ×Ö¾××œ×¤×× ×•××¨×™); ××¡×¤×¨×™×: ×’×‘×•×œ×•×ª regex
  static bool _termMatches(String text, String term) {
    final textNorm = _normalize(text);
    final t = _normalize(term);
    if (t.isEmpty) return false;
    if (_isAllDigits(t)) {
      final pattern = '(^|\\D)' + RegExp.escape(t) + r'(\D|$)';
      return RegExp(pattern).hasMatch(textNorm);
    }
    return textNorm.contains(t);
  }

  /// ×”×ª×××ª ××™×œ×” ×©×œ××” ×‘×ª×•×›×Ÿ â€” ×’×‘×•×œ×•×ª: ×œ× ××•×ª/×¡×¤×¨×” (×¢×‘×¨×™×ª/×× ×’×œ×™×ª) ×œ×¤× ×™ ×•××—×¨×™
  static bool _wholeWordInContent(String contentWithSpaces, String term) {
    final t = _norm(term);
    if (t.isEmpty || contentWithSpaces.isEmpty) return false;
    final escaped = RegExp.escape(t);
    // [^\w] = ×œ× ××•×ª/×¡×¤×¨×”; unicode: true ×›×“×™ ×©Ö¾\w ×™×›×œ×•×œ ×¢×‘×¨×™×ª
    final boundary = RegExp('(^|[^\\w])' + escaped + r'([^\w]|$)', unicode: true);
    return boundary.hasMatch(contentWithSpaces);
  }

  /// × ×ª×™×‘ ×”×ª×™×§×™×™×” (×œ×œ× ×©× ×”×§×•×‘×¥) â€” ×œ×—×™×©×•×‘ locationText
  static String _locationText(FileMetadata file) {
    final p = file.path;
    final i = p.lastIndexOf(RegExp(r'[/\\]'));
    if (i <= 0) return '';
    return p.substring(0, i);
  }

  /// ×¡×•×¤×¨ ×›××” ×–×•×’×•×ª ×¡××•×›×™× (××•× ×—-××•× ×—) ××”×©××™×œ×ª×” ××•×¤×™×¢×™× consecutively ×‘×ª×•×›×Ÿ â€” ×›×œ ×–×•×’ × ×¡×¤×¨ ×¤×¢× ××—×ª
  static int _countUniqueAdjacentPairs(List<String> rawTerms, String contentWithSpaces) {
    if (contentWithSpaces.isEmpty) return 0;
    final terms = rawTerms.map((t) => _norm(t)).where((s) => s.isNotEmpty).toList();
    if (terms.length < 2) return 0;
    final queryPairs = <String>{};
    for (var i = 0; i < terms.length - 1; i++) {
      queryPairs.add('${terms[i]} ${terms[i + 1]}');
    }
    final words = contentWithSpaces
        .split(RegExp(r'\s+'))
        .map((s) => _norm(s))
        .where((s) => s.isNotEmpty)
        .toList();
    if (words.length < 2) return 0;
    final foundPairs = <String>{};
    for (var i = 0; i < words.length - 1; i++) {
      final pair = '${words[i]} ${words[i + 1]}';
      if (queryPairs.contains(pair)) foundPairs.add(pair);
    }
    return foundPairs.length;
  }

  /// ××—×©×‘ ×¦×™×•×Ÿ + ×¤×™×¨×•×˜: filename, location, ×ª×•×›×Ÿ
  /// ××©×§×œ×™× ×“×™× ××™×™×: RankingConfig ××ª×¢×“×›×Ÿ ×-syncDictionaryWithServer (rankingConfig ××”×©×¨×ª)
  static (double, String) _scoreWithBreakdown(FileMetadata file, List<String> rawTerms,
      List<String> synonymTerms, String fnLower, String locLower, String extLower,
      String extRaw, String exactPhrase) {
    final config = RankingConfig.instance;
    final ptsFilename = config.filenameWeight;
    final ptsLocation = config.pathWeight;
    final maxContentScore = config.contentWeight;
    final exactPhraseBonus = config.exactPhraseBonus;
    final multiWordFullBonus = config.fullMatchMultiplier;

    final rawSet = rawTerms.map((t) => _norm(t)).toSet();
    final termsFound = <String>{};
    final contentTermsFound = <String>{};
    double score = 0;
    double namePts = 0, locPts = 0;

    double densityFactor(String term, int foundTokenLen) {
      if (foundTokenLen <= 0) return 1.0;
      final factor = term.length / foundTokenLen;
      return factor > 1.0 ? 1.0 : factor;
    }

    void addPts(String term, bool isRaw) {
      final t = _norm(term);
      if (t.isEmpty) return;
      final pts = isRaw ? 1.0 : _synonymFactor;
      if (_termMatches(fnLower, term)) {
        termsFound.add(t);
        final factor = densityFactor(t, fnLower.length);
        namePts += ptsFilename * pts * factor;
      }
      if (_termMatches(locLower, term)) {
        termsFound.add(t);
        final factor = densityFactor(t, locLower.length);
        locPts += ptsLocation * pts * factor;
      }
      // ×ª×•×›×Ÿ: ×¡×•×¤×¨×™× ×¨×§ ××•× ×—×™ ×©××™×œ×ª×” (raw) ×©××•×¤×™×¢×™× â€” ×¦×™×•×Ÿ ×œ×¤×™ Query Coverage Ratio
      final inContent = extRaw.isNotEmpty && (_wholeWordInContent(extRaw, term) || extLower.contains(t));
      if (inContent) {
        termsFound.add(t);
        if (isRaw) contentTermsFound.add(t);
      }
    }

    for (final term in rawTerms) {
      addPts(term, true);
    }
    for (final term in synonymTerms) {
      if (rawSet.contains(_norm(term))) continue;
      addPts(term, false);
    }

    final queryWordCount = rawTerms.isEmpty ? 0 : rawTerms.length;
    final weightPerWord = queryWordCount > 0 ? maxContentScore / queryWordCount : 0.0;
    final contentScore = contentTermsFound.length * weightPerWord;
    score = namePts + locPts + contentScore;

    // ×‘×•× ×•×¡ ×¡××™×›×•×ª â€” ××•× ×—×™× ×©××•×¤×™×¢×™× consecutively ×‘×ª×•×›×Ÿ (×›×œ ×–×•×’ ×™×™×—×•×“×™ × ×¡×¤×¨ ×¤×¢× ××—×ª)
    final adjacencyCount = _countUniqueAdjacentPairs(rawTerms, extRaw);
    score += (adjacencyCount > _adjacentPairCap ? _adjacentPairCap : adjacencyCount) * _adjacentPairBonus;

    // Drive: ×‘×•× ×•×¡ ××˜××“××˜×” â€” ×”×ª×××•×ª ×‘×©× ×§×•×‘×¥ ×©×•×§×œ×•×ª ×™×•×ª×¨ (××™×Ÿ OCR)
    if (file.isCloud && namePts > 0) {
      score += _driveMetadataBonus;
    }

    // ×¢×“×™×¤×•×ª ×©×¤×”: ×‘×•× ×•×¡ ×œ×©× ×¢×‘×¨×™ × ×§×™, ×§× ×¡ ×œ×©× ××¢×¨×›×ª (GUID, pdf.123)
    final baseName = fnLower.contains('.') ? fnLower.substring(0, fnLower.lastIndexOf('.')) : fnLower;
    if (baseName.length >= 20 && _guidLikeName.hasMatch(baseName)) {
      score += _crypticNamePenalty;
    } else if (_pdfDotNumbers.hasMatch(fnLower)) {
      score += _crypticNamePenalty;
    }

    // Exact phrase bonus â€” ×”×ª×××” ××“×•×™×§×ª (×œ××—×¨ × ×¨××•×œ ×¨×•×•×—×™×/×©×•×¨×•×ª)
    if (exactPhrase.length >= 2) {
      final phraseNorm = _normalize(exactPhrase);
      final fnNorm = _normalize(fnLower);
      final extNorm = _normalize(extLower);
      if (fnNorm.contains(phraseNorm) || extNorm.contains(phraseNorm)) {
        score += exactPhraseBonus;
      }
    }

    // Multi-Word â€” ×§× ×¡ ×¢×œ ×”×ª×××” ×—×œ×§×™×ª; ×‘×•× ×•×¡ + ××›×¤×™×œ ×¢×œ ×”×ª×××” ××œ××”
    final totalQueryTerms = rawTerms.length;
    if (totalQueryTerms > 0) {
      final rawNormSet = rawTerms.map((t) => _norm(t)).toSet();
      final termsFoundCount = rawNormSet.intersection(termsFound).length;
      final matchRatio = termsFoundCount / totalQueryTerms;
      if (matchRatio < 0.5) {
        score *= _multiWordSeverePenalty;
      } else if (matchRatio >= 1.0) {
        score = (score * multiWordFullBonus) + _multiWordFullBonusAdd;
      }
    }

    // AI Metadata â€” ×”×ª×××” ×œÖ¾category ××• tags
    final cat = file.category?.toLowerCase();
    final aiTags = file.tags?.map((t) => t.toLowerCase()).toList();
    if (cat != null || (aiTags != null && aiTags.isNotEmpty)) {
      for (final term in rawTerms) {
        final t = _norm(term);
        if (t.isEmpty) continue;
        if (cat != null && (cat == t || cat.contains(t))) {
          score += _aiMetadataBonus;
          break;
        }
        if (aiTags != null && aiTags.any((tag) => tag == t || tag.contains(t))) {
          score += _aiMetadataBonus;
          break;
        }
      }
    }

    final parts = <String>[];
    if (namePts != 0) parts.add('Fn(${_fmtScore(namePts)})');
    if (locPts != 0) parts.add('Loc(${_fmtScore(locPts)})');
    if (contentScore != 0) parts.add('Content(${_fmtScore(contentScore)})');
    if (adjacencyCount > 0) parts.add('Adj($adjacencyCount)');
    if (rawTerms.isNotEmpty) {
      final rawNormSet = rawTerms.map((t) => _norm(t)).toSet();
      final termsFoundCount = rawNormSet.intersection(termsFound).length;
      final matchRatio = termsFoundCount / rawTerms.length;
      if (matchRatio < 0.5) {
        parts.add('MultiWordÃ—$_multiWordSeverePenalty');
      } else if (matchRatio >= 1.0) {
        parts.add('MultiWord(x1.2+50)');
      }
    }
    if (exactPhrase.length >= 2) {
      final phraseNorm = _normalize(exactPhrase);
      final fnNorm = _normalize(fnLower);
      final extNorm = _normalize(extLower);
      if (fnNorm.contains(phraseNorm) || extNorm.contains(phraseNorm)) {
        parts.add('Exact+$exactPhraseBonus');
      }
    }
    if (baseName.length >= 20 && _guidLikeName.hasMatch(baseName)) {
      parts.add('Cryptic($_crypticNamePenalty)');
    } else if (_pdfDotNumbers.hasMatch(fnLower)) {
      parts.add('Cryptic($_crypticNamePenalty)');
    }
    if (cat != null || (aiTags != null && aiTags.isNotEmpty)) {
      var aiMatch = false;
      for (final term in rawTerms) {
        final t = _norm(term);
        if (t.isEmpty) continue;
        if (cat != null && (cat == t || cat.contains(t))) { aiMatch = true; break; }
        if (aiTags != null && aiTags.any((tag) => tag == t || tag.contains(t))) { aiMatch = true; break; }
      }
      if (aiMatch) parts.add('AI($_aiMetadataBonus)');
    }
    if (file.isCloud && namePts > 0) parts.add('Drive+$_driveMetadataBonus');

    final breakdown = parts.isEmpty ? 'No match' : parts.join(' + ');
    return (score, breakdown);
  }

  /// × ×¨××•×œ ×œ××•× ×—: trim + lowercase â€” ×œ×œ× ×”×¡×¨×ª ×¡×¤×¨×•×ª (×ª××™×›×” ×‘Ö¾"185", "2024", "106")
  static String _norm(String s) => s.trim().toLowerCase();

  /// ×¤×•×¨××˜ ×¦×™×•×Ÿ ×œ×“×™×‘×•×’ â€” ××¡×¤×¨ ×©×œ× ××• ×¢×©×¨×•× ×™ ××—×“
  static String _fmtScore(double d) =>
      d == d.roundToDouble() ? d.toInt().toString() : d.toStringAsFixed(1);

  /// × ×¨××•×œ ×œ×˜×§×¡×˜ ×Ö¾PDF: ×”×¡×¨×ª × ×™×§×•×“, ×¨×•×•×—×™× ××¨×•×‘×™×, ×ª×•×•×™× ×œ×Ö¾××œ×¤×× ×•××¨×™×™× ("×§ ×‘ ×œ ×”" â†’ "×§×‘×œ×”").
  /// Regex: [^a-z0-9\u0590-\u05FF] â€” ×¡×¤×¨×•×ª 0â€“9 × ×©××¨×•×ª (×—×™×¤×•×© ××¡×¤×¨×™× × ×ª××š).
  static String _normalize(String input) {
    var s = input.trim().toLowerCase();
    // ×”×¡×¨×ª × ×™×§×•×“ ×¢×‘×¨×™ (U+0591â€“U+05BD, U+05BFâ€“U+05C2, U+05C4â€“U+05C7)
    s = s.replaceAll(RegExp(r'[\u0591-\u05BD\u05BF-\u05C2\u05C4-\u05C7]'), '');
    s = s.replaceAll(RegExp(r'\s+'), '');
    // ×©××™×¨×” ×¨×§ ×¢×œ ××•×ª×™×•×ª (×›×•×œ×œ ×¢×‘×¨×™×ª) ×•×¡×¤×¨×•×ª â€” ×˜×™×¤×•×œ ×‘Ö¾"H e b r e w" / "×§.×‘.×œ.×”"
    return s.replaceAll(RegExp(r'[^a-z0-9\u0590-\u05FF]'), '');
  }

  /// ××“×¨×’ ×•××™×™×Ÿ ×§×‘×¦×™× ×œ×¤×™ ×¦×™×•×Ÿ ×¨×œ×•×•× ×˜×™×•×ª; ×××œ× debugScore/debugScoreBreakdown; ×œ×•×’ Top 5
  static List<FileMetadata> rankAndSort(List<FileMetadata> files, SearchIntent intent) {
    if (files.isEmpty) return files;
    if (intent.rawTerms.isEmpty && intent.terms.isEmpty) {
      for (final f in files) {
        f.debugScore = null;
        f.debugScoreBreakdown = null;
      }
      files.sort((a, b) => b.lastModified.compareTo(a.lastModified));
      return files;
    }

    final rawSet = intent.rawTerms.map((t) => _norm(t)).toSet();
    final synonymTerms = intent.terms.where((t) => !rawSet.contains(_norm(t))).toList();

    final exactPhrase = intent.rawTerms.join(' ');
    final scored = files.map((file) {
      final fn = file.name;
      final loc = _locationText(file);
      final ext = file.extractedText ?? '';
      final extRaw = ext.trim().toLowerCase();
      final fnLower = _norm(fn);
      final locLower = _norm(loc);
      final extLower = _norm(ext);
      final (score, breakdown) = _scoreWithBreakdown(
          file, intent.rawTerms, synonymTerms, fnLower, locLower, extLower, extRaw, exactPhrase);
      file.debugScore = score;
      file.debugScoreBreakdown = breakdown;
      return _ScoredFile(file, score);
    }).toList();

    scored.sort((a, b) {
      final cmp = b.score.compareTo(a.score);
      if (cmp != 0) return cmp;
      return b.file.lastModified.compareTo(a.file.lastModified);
    });

    // ×œ×•×’ Top 5
    final top5 = scored.take(5).toList();
    for (var i = 0; i < top5.length; i++) {
      final e = top5[i];
      debugPrint(
          'ğŸ† Rank #${i + 1}: ${e.file.name} - Score: ${e.score.toStringAsFixed(1)} (${e.file.debugScoreBreakdown ?? ""})');
    }

    return scored.map((e) => e.file).toList();
  }
}

class _ScoredFile {
  final FileMetadata file;
  final double score;
  _ScoredFile(this.file, this.score);
}
